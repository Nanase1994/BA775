{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W23LcRScf6-S"
      },
      "source": [
        "# GPT Chat Completion Lab\n",
        "\n",
        "Welcome! In this mini-lab we will explore how to build a playful yet practical chat assistant using the GPT 5 models. The goal is to make the workflow clear enough for beginners while giving you a template you can adapt for your usecases.\n",
        "\n",
        "Objectives:\n",
        "- Build a basic GPT-powered chat assistant  \n",
        "- Adjust assistant behavior using system prompts  \n",
        "- Build a simple Gradio UI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i55vtKX9f6-U"
      },
      "source": [
        "## Game Plan\n",
        "- **Context:** We are using Google Colab, so everything happens in the cloud.\n",
        "- **Model:** `gpt-5-nano` keeps responses smart while staying cost-efficient.\n",
        "- **Secret management:** We read the API key from the Colab secret named `OpenAI_API_Key`.\n",
        "- **Flow:** install the SDK â†’ load the key securely â†’ define a helper function â†’ experiment with prompts.\n",
        "- **Stretch idea:** tweak the conversation style and system prompt with your own ideas.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "MODEL=\"gpt-5-nano\""
      ],
      "metadata": {
        "id": "6V2GzCq47uqQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90urDtAwf6-V"
      },
      "source": [
        "## Load Secrets (No Hard-Coding!)\n",
        "Colab lets us keep keys in the `userdata` vault. Make sure your workspace already stores `OpenAI_API_Key`; otherwise run `userdata.set_secret` once (never share the value).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bTQdB0Yvf6-V"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = userdata.get('OpenAI_API_Key')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou_qMNtYf6-V"
      },
      "source": [
        "## Wrap the GPT Client\n",
        "We use the official `openai` package. The helper below:\n",
        "1. Initializes a single `OpenAI` client.\n",
        "2. Accepts a system message and a list of user turns.\n",
        "3. Returns the model reply plus token usage so we can discuss cost control.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=MODEL,\n",
        "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
        ")\n",
        "\n",
        "response"
      ],
      "metadata": {
        "id": "wXdFkxJ3iugG",
        "outputId": "95ffcd4f-0c22-4cc4-aef2-0a6962bdd2a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Response(id='resp_062912d2fbb3b52600691ccff3749881a3a520887bad494c70', created_at=1763495923.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_062912d2fbb3b52600691ccff3a68c81a39acb595b40bf7165', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_062912d2fbb3b52600691ccff5615c81a398c6773692f8e312', content=[ResponseOutputText(annotations=[], text='Under the silver moon, a gentle unicorn trotted through a lullaby-soft forest and whispered sweet dreams to the sleepy stars.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=17, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=351, output_tokens_details=OutputTokensDetails(reasoning_tokens=320), total_tokens=368), user=None, billing={'payer': 'developer'}, prompt_cache_retention=None, store=True)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.usage.output_tokens"
      ],
      "metadata": {
        "id": "xh9yN9STz4nr",
        "outputId": "ac777349-9c8a-493e-9023-312c6bf986f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "351"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's extract the reply part only:"
      ],
      "metadata": {
        "id": "e6a9hT4ckUH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.output_text)"
      ],
      "metadata": {
        "id": "EDGGZasgjiQe",
        "outputId": "11f00202-a3b3-4872-afb5-c2404944ab24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Under the silver moon, a gentle unicorn trotted through a lullaby-soft forest and whispered sweet dreams to the sleepy stars.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System Instructions\n",
        "Formerly known as system/developer prompt. The instructions parameter sets high-level guidance for how the model should behaveâ€”its tone, goals, and styleâ€”while message roles give more specific, task-level directions.\n"
      ],
      "metadata": {
        "id": "dnc_cKFBpPy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/soltaniehha/Business-Analytics-Toolbox/master/docs/images/Prof-Owl-1.png\"\n",
        "     width=\"300\">\n"
      ],
      "metadata": {
        "id": "3cgtRdAerkMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = \"You are Professor Owl, a wise but approachable teacher. Give clear, simple explanations and gently guide students without sounding formal.\"\n",
        "input = \"why do data analysts prefer Python or SQL instead of Excel for big datasets?\"\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=MODEL,\n",
        "    instructions=instructions,   # Formerly known as system prompt\n",
        "    input=input,                 # User prompt\n",
        "    text={ \"verbosity\": \"low\" }  # Low: short, concise outputs â€” High: detailed explanations or big refactors\n",
        ")\n",
        "\n",
        "Markdown(response.output_text)"
      ],
      "metadata": {
        "id": "jQWnIpPglvV6",
        "outputId": "b148ae3c-d23c-4c74-c78e-dd7916f56ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Great question. Hereâ€™s the simple reality: Excel is great for small, quick analyses, but Python and SQL are built for bigger, repeatable work. Hereâ€™s why:\n\n- Size and speed\n  - Excel has a hard row limit (about 1 million rows per sheet) and can get very slow with large formulas or many sheets.\n  - SQL databases and Python data tools are designed to handle large datasets efficiently, using indexing, streaming, and parallel processing.\n\n- Memory and resources\n  - Excel loads data into memory, which means big files can crash or become sluggish.\n  - SQL runs on a database server; Python can process data in chunks or with out-of-core libraries (e.g., Dask) to avoid loading everything at once.\n\n- Reproducibility and automation\n  - Excel often involves manual steps, copy-paste, and ad-hoc formulas, which are easy to break and hard to reproduce.\n  - SQL and Python scripts can be version-controlled, tested, and rerun automatically to produce the same results every time.\n\n- Data integrity and governance\n  - With Excel, multiple copies of the same data can exist in different files, leading to inconsistencies.\n  - A centralized database plus scripted workflows keep a single source of truth and clear provenance.\n\n- Manipulation capabilities\n  - SQL shines at joining large tables, filtering, aggregating, and doing set-based operations efficiently.\n  - Python (with pandas, pyarrow, etc.) is very flexible for cleaning, feature engineering, and complex transformations, especially when logic is iterative.\n\n- Collaboration and sharing\n  - Databases and code-based workflows are easier to share, review, and run in teams.\n  - Excel files are easier for individuals but harder to manage at scale and in production.\n\nWhen to use Excel still:\n- Quick exploration on small datasets\n- Final tweaks or simple dashboards\n- One-off analyses that donâ€™t need repetition\n\nBottom line: for big datasets and scalable, repeatable analysis, SQL and Python are usually the better tools. Use Excel for quick, light tasks, not as the primary tool for large-scale data work."
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat History"
      ],
      "metadata": {
        "id": "Y-aeunFKv32y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep history\n",
        "history = [{\"role\": \"developer\", \"content\": instructions}]\n",
        "\n",
        "def chat(message):\n",
        "    history.append({\"role\": \"user\", \"content\": message})  # Add the new user message to history\n",
        "\n",
        "    # Send entire history to the model\n",
        "    response = client.responses.create(\n",
        "        model=MODEL,\n",
        "        input=history,\n",
        "        text={ \"verbosity\": \"low\" }\n",
        "    )\n",
        "\n",
        "    # Add model response to history\n",
        "    history.append({\"role\": \"assistant\", \"content\": response.output_text})\n",
        "\n",
        "    return response.output_text"
      ],
      "metadata": {
        "id": "VjSQ771duhdJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(chat(input))"
      ],
      "metadata": {
        "id": "JloK9KRtujRr",
        "outputId": "fa56e404-3188-4554-a82a-1a1dcd59174c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Great question. In short: for big datasets, Python or SQL usually wins because theyâ€™re designed for scale, automation, and reproducibility. Hereâ€™s why:\n\n- Size and speed\n  - Excel hits a row limit (about 1 million rows) and can bog down or crash with big data.\n  - SQL databases and Python (with proper tooling) handle much larger data efficiently (indexes, querying, streaming, chunking).\n\n- Power of data operations\n  - Excel is great for light, ad-hoc calculations.\n  - SQL can join large tables, filter, group, and use indexes. Python (pandas, Dask) can do complex transformations, analytics, and even ML.\n\n- Reproducibility and automation\n  - Excel is manual and error-prone; changes arenâ€™t easy to track.\n  - Code and queries can be version-controlled, automated in pipelines, and re-run with consistent results.\n\n- Data integrity and governance\n  - Databases enforce schemas, types, constraints, and access controls.\n  - Excel workbooks can become inconsistent, with multiple copies and hidden changes.\n\n- Ecosystem and collaboration\n  - Python/SQL fit into data pipelines, dashboards, ML, and scalable storage; workflows are easier to share and audit.\n\n- When Excel is okay\n  - Small datasets, quick exploration, or when you need a simple, visual summary.\n\nIf youâ€™re dealing with big data, start with SQL for querying and Python for deeper analysis or modeling."
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat(\"Please highlight the most important point\")"
      ],
      "metadata": {
        "id": "4dPpqHsRwGfo",
        "outputId": "42839805-0444-4911-a992-8cb74db71b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Key point: For big datasets, SQL and Python are preferred because they scale, automate, and give reproducible results, while Excel struggles with size and consistency.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "id": "SLIJdBtjuk-9",
        "outputId": "56b52e02-af9e-41fc-97b3-79f28757e028",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'developer',\n",
              "  'content': 'You are Professor Owl, a wise but approachable teacher. Give clear, simple explanations and gently guide students without sounding formal.'},\n",
              " {'role': 'user',\n",
              "  'content': 'why do data analysts prefer Python or SQL instead of Excel for big datasets?'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Great question. In short: for big datasets, Python or SQL usually wins because theyâ€™re designed for scale, automation, and reproducibility. Hereâ€™s why:\\n\\n- Size and speed\\n  - Excel hits a row limit (about 1 million rows) and can bog down or crash with big data.\\n  - SQL databases and Python (with proper tooling) handle much larger data efficiently (indexes, querying, streaming, chunking).\\n\\n- Power of data operations\\n  - Excel is great for light, ad-hoc calculations.\\n  - SQL can join large tables, filter, group, and use indexes. Python (pandas, Dask) can do complex transformations, analytics, and even ML.\\n\\n- Reproducibility and automation\\n  - Excel is manual and error-prone; changes arenâ€™t easy to track.\\n  - Code and queries can be version-controlled, automated in pipelines, and re-run with consistent results.\\n\\n- Data integrity and governance\\n  - Databases enforce schemas, types, constraints, and access controls.\\n  - Excel workbooks can become inconsistent, with multiple copies and hidden changes.\\n\\n- Ecosystem and collaboration\\n  - Python/SQL fit into data pipelines, dashboards, ML, and scalable storage; workflows are easier to share and audit.\\n\\n- When Excel is okay\\n  - Small datasets, quick exploration, or when you need a simple, visual summary.\\n\\nIf youâ€™re dealing with big data, start with SQL for querying and Python for deeper analysis or modeling.'},\n",
              " {'role': 'user', 'content': 'Please highlight the most important point'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Key point: For big datasets, SQL and Python are preferred because they scale, automate, and give reproducible results, while Excel struggles with size and consistency.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chatbot\n",
        "Using `Gradio` to build a chatbot that we control its workflow."
      ],
      "metadata": {
        "id": "YhN0hJx-wjzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = \"You are Professor Owl, a wise but friendly teacher of Business Analytics. Explain concepts clearly and simply, using gentle guidance.\"\n",
        "\n",
        "def respond(message, history):\n",
        "    messages = [{\"role\": \"developer\", \"content\": instructions}]\n",
        "    messages.extend({\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in history)\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "\n",
        "    response = client.responses.create(\n",
        "        model=MODEL,\n",
        "        input=messages,\n",
        "        text={\"verbosity\": \"low\"}\n",
        "    )\n",
        "    return response.output_text\n",
        "\n",
        "demo = gr.ChatInterface(\n",
        "    respond,\n",
        "    type=\"messages\",\n",
        "    title=\"ðŸ¦‰ Professor Owl â€“ Business Analytics Helper\",\n",
        "    description=\"Ask Professor Owl anything data analytics!\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)  # Add debug=True to debug, if needed"
      ],
      "metadata": {
        "id": "lQtzyh2Exyo1",
        "outputId": "7649fcca-3f2c-4202-f16b-96f15759f7b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f9dc499acb65c87bc3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f9dc499acb65c87bc3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hfh6W_6f6-W"
      },
      "source": [
        "## Your Turn\n",
        "Plug in your own scenario: Rephrase the instructions to shift tone/guidelines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcHECt7Uf6-W"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}